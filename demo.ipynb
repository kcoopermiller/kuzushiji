{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchmetrics\n",
    "import lightning as L\n",
    "from models import AutoEncoder, MambaImgClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import learn2learn as l2l\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KuzushijiMNISTDataset(Dataset):\n",
    "    def __init__(self, imgs_npz_file, labels_npz_file, transform=None):\n",
    "        imgs_data = np.load(imgs_npz_file)\n",
    "        labels_data = np.load(labels_npz_file)\n",
    "        self.images = imgs_data['arr_0']\n",
    "        self.labels = labels_data['arr_0']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # add more transforms if needed (channels first?)\n",
    "])\n",
    "train_dataset = KuzushijiMNISTDataset('dataset/npz/kmnist-train-imgs.npz', \n",
    "                                      'dataset/npz/kmnist-train-labels.npz', \n",
    "                                      transform=transform)\n",
    "val_dataset = KuzushijiMNISTDataset('dataset/npz/kmnist-test-imgs.npz', \n",
    "                                    'dataset/npz/kmnist-test-labels.npz', \n",
    "                                    transform=transform)\n",
    "\n",
    "# Instantiate the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderLightning(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = AutoEncoder()\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch  # We don't need labels for autoencoder training\n",
    "        x = x.view(x.size(0), -1)  # Flatten the images\n",
    "        x_hat = self(x)\n",
    "        loss = self.loss(x_hat, x)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_hat = self(x)\n",
    "        val_loss = self.loss(x_hat, x)\n",
    "        self.log('val_loss', val_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Display the original and reconstructed images at the end of the training\n",
    "    def on_fit_end(self) -> None:\n",
    "        x, _ = next(iter(self.trainer.val_dataloaders))\n",
    "        x = x.view(x.size(0), -1).to(self.device)\n",
    "        x_hat = self(x)\n",
    "        # Select a few images to visualize\n",
    "        x = x.view(-1, 1, 28, 28)[:6].cpu()\n",
    "        x_hat = x_hat.view(-1, 1, 28, 28)[:6].cpu()\n",
    "        \n",
    "        fig, axs = plt.subplots(2, 6, figsize=(15, 5))\n",
    "        for i in range(6):\n",
    "            axs[0, i].imshow(x[i].squeeze().numpy(), cmap='gray')\n",
    "            axs[0, i].axis('off')\n",
    "            axs[1, i].imshow(x_hat[i].squeeze().detach().numpy(), cmap='gray')\n",
    "            axs[1, i].axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = AutoEncoderLightning()\n",
    "\n",
    "trainer = L.Trainer(max_epochs=10)\n",
    "trainer.fit(lightning_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgClassifierLightning(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "patch_size = 4\n",
    "img_size = 28\n",
    "embed_dim = 256\n",
    "dropout = 0.1\n",
    "n_layers = 6\n",
    "n_channels = 1\n",
    "\n",
    "model = MambaImgClassifier(patch_size, img_size, n_channels, embed_dim, n_layers, dropout)\n",
    "\n",
    "# Wrap in Lightning module\n",
    "lightning_model = ImgClassifierLightning(model)\n",
    "\n",
    "# Trainer\n",
    "trainer = L.Trainer(max_epochs=5)\n",
    "trainer.fit(lightning_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba w/ MAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not working properly yet. I need to figure out how to create a better task sampler and adjust the training loop accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAMLLightning(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3, steps=1, lr_inner=0.01):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.maml = l2l.algorithms.MAML(self.model, lr=lr_inner, first_order=False)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.steps = steps  # Number of adaptation steps for each task\n",
    "        self.lr_inner = lr_inner  # Learning rate for task-specific adaptation\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        return self.maml(x)\n",
    "\n",
    "    # TODO: https://github.com/learnables/learn2learn/blob/master/examples/vision/meta_mnist.py\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # Create a fast model using the current meta model\n",
    "        learner = self.maml.clone()  # Create a clone of the model for this task\n",
    "        for _ in range(self.steps):\n",
    "            y_hat = learner(x)\n",
    "            task_loss = F.cross_entropy(y_hat, y)\n",
    "            learner.adapt(task_loss)\n",
    "\n",
    "        # Compute loss on the adapted model to update the meta-model\n",
    "        y_hat = learner(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Update the meta-model parameters, not the adapted model parameters\n",
    "        return torch.optim.Adam(self.maml.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = l2l.data.MetaDataset(train_dataset)\n",
    "\n",
    "train_tasks = l2l.data.Taskset(\n",
    "    train_dataset,\n",
    "    task_transforms=[\n",
    "        l2l.data.transforms.NWays(train_dataset, 5),\n",
    "        l2l.data.transforms.KShots(train_dataset, 2),\n",
    "        l2l.data.transforms.LoadData(train_dataset),\n",
    "        l2l.data.transforms.RemapLabels(train_dataset),\n",
    "        l2l.data.transforms.ConsecutiveLabels(train_dataset),\n",
    "    ],\n",
    "    num_tasks=1000,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_tasks, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 4\n",
    "img_size = 28\n",
    "embed_dim = 256\n",
    "dropout = 0.1\n",
    "n_layers = 6\n",
    "n_channels = 1\n",
    "\n",
    "model = MambaImgClassifier(patch_size, img_size, n_channels, embed_dim, n_layers, dropout)\n",
    "lightning_model = MAMLLightning(model)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=5)\n",
    "trainer.fit(lightning_model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
