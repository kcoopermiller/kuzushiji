# Kuzushiji Recognition

Currently, this repo contains a [Mamba](https://github.com/state-spaces/mamba)-based model trained on the [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist) dataset (not really relevant, I just wanted to play around with the KMNIST dataset and the Mamba model)

## Ideas
**Improvement in Generalization on Kanji Characters**
- [The Curse of Low Task Diversity: On the Failure of Transfer Learning to Outperform MAML and Their Empirical Equivalence](https://arxiv.org/abs/2208.01545)
- [Introduction to Model-Agnostic Meta-Learning](https://interactive-maml.github.io/)
- [Few-Shot Learning & Meta-Learning](https://www.borealisai.com/research-blogs/tutorial-2-few-shot-learning-and-meta-learning-i/)
- [Brando Miranda's Work](https://brando90.github.io/brandomiranda/publications.html)

## Other References

- [Tarin Clanuwat's work](https://tkasasagi.github.io/)
- [KuroNet Dataset](http://codh.rois.ac.jp/char-shape/book/)
- [Kuzushiji-MNIST](https://github.com/rois-codh/kmnist)
- [Deep Learning for Classical Japanese Literature](https://arxiv.org/abs/1812.01718) 
- [Survey on Deep Learning-based Kuzushiji Recognition](https://arxiv.org/abs/2007.09637)
- [UPenn Japanese Digital Resources: Kuzushiji](https://guides.library.upenn.edu/japanesedigitalresources/kuzushiji)



**MoE**
- [Residual Mixture of Experts](https://arxiv.org/pdf/2204.09636.pdf)
- [Deep Mixture of Experts via Shallow Embedding](http://proceedings.mlr.press/v115/wang20d/wang20d.pdf)
